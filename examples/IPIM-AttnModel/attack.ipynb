{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.utils as utils\n",
    "import torchvision.transforms as torch_transforms\n",
    "from networks import AttnVGG, VGG\n",
    "from loss import FocalLoss\n",
    "from data import preprocess_data_2016, preprocess_data_2017, ISIC\n",
    "from utilities import *\n",
    "from transforms import *\n",
    "\n",
    "print(\"======>load pretrained models\")\n",
    "net = AttnVGG(num_classes=2, attention=True, normalize_attn=True)\n",
    "# net = VGG(num_classes=2, gap=False)\n",
    "checkpoint = torch.load('models/checkpoint.pth')\n",
    "net.load_state_dict(checkpoint['state_dict'])\n",
    "pretrained_clf = nn.DataParallel(net).cuda()\n",
    "pretrained_clf.eval()\n",
    "\n",
    "print(\"=======>load ISIC2016 dataset\")\n",
    "normalize = Normalize((0.7012, 0.5517, 0.4875), (0.0942, 0.1331, 0.1521))\n",
    "transform_test = torch_transforms.Compose([\n",
    "         RatioCenterCrop(0.8),\n",
    "         Resize((256,256)),\n",
    "         CenterCrop((224,224)),\n",
    "         ToTensor(),\n",
    "         normalize\n",
    "    ])\n",
    "testset = ISIC(csv_file='test.csv', transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False, num_workers=8)\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with open('test_results.csv', 'wt', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        images_test, labels_test = data['image'], data['label']\n",
    "        images_test, labels_test = images_test.cuda(), labels_test.cuda()\n",
    "        pred_test, __, __ = pretrained_clf.forward(images_test)\n",
    "        predict = torch.argmax(pred_test, 1)\n",
    "        total += labels_test.size(0)\n",
    "        correct += torch.eq(predict, labels_test).sum().double().item()\n",
    "        # record test predicted responses\n",
    "        responses = F.softmax(pred_test, dim=1).squeeze().detach().cpu().numpy()\n",
    "        responses = [responses[i] for i in range(responses.shape[0])]\n",
    "        csv_writer.writerows(responses)\n",
    "        # log images\n",
    "        if True:\n",
    "            I_test = utils.make_grid(images_test, nrow=8, normalize=True, scale_each=True)\n",
    "            #writer.add_image('test/image', I_test, i)\n",
    "            torchvision.utils.save_image(images_test, \"test/test_image.jpg\", nrow=8, normalize=True)\n",
    "            # accention maps\n",
    "            if True:\n",
    "                __, a1, a2 = pretrained_clf.forward(images_test)\n",
    "                if a1 is not None:\n",
    "                    attn1 = visualize_attn(I_test, a1, up_factor=8, nrow=8)\n",
    "                    torchvision.utils.save_image(attn1, \"test/att1.jpg\")\n",
    "                    #writer.add_image('test/attention_map_1', attn1, i)\n",
    "                if a2 is not None:\n",
    "                    attn2 = visualize_attn(I_test, a2, up_factor=2*8, nrow=8)\n",
    "                    torchvision.utils.save_image(attn2, \"test/att2.jpg\")\n",
    "                    #writer.add_image('test/attention_map_2', attn2, i)\n",
    "AP, AUC, precision_mean, precision_mel, recall_mean, recall_mel = compute_metrics('test_results.csv', 'test.csv')\n",
    "print(\"\\ntest result: accuracy %.2f%%\" % (100*correct/total))\n",
    "print(\"\\nmean precision %.2f%% mean recall %.2f%% \\nprecision for mel %.2f%% recall for mel %.2f%%\" %\n",
    "        (100*precision_mean, 100*recall_mean, 100*precision_mel, 100*recall_mel))\n",
    "print(\"\\nAP %.4f AUC %.4f\\n\" % (AP, AUC))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libadver.attack as attack\n",
    "(./xx.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======>load pretrained models\n",
      "=======>load ISIC2016 dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.utils as utils\n",
    "import torchvision.transforms as torch_transforms\n",
    "from networks import AttnVGG, VGG\n",
    "from loss import FocalLoss\n",
    "from data import preprocess_data_2016, preprocess_data_2017, ISIC\n",
    "from utilities import *\n",
    "from transforms import *\n",
    "import libadver.attack as attack\n",
    "\n",
    "modelFile = \"/home/lrh/program/git/pytorch-example/adversarial-miccai2019/isic2016/IPMI2019-AttnMel/models/checkpoint.pth\"\n",
    "testCSVFile = \"/home/lrh/program/git/pytorch-example/adversarial-miccai2019/isic2016/IPMI2019-AttnMel/test.csv\"\n",
    "trainCSVFile = \"/home/lrh/program/git/pytorch-example/adversarial-miccai2019/isic2016/IPMI2019-AttnMel/train.csv\"\n",
    "\n",
    "print(\"======>load pretrained models\")\n",
    "net = AttnVGG(num_classes=2, attention=True, normalize_attn=True, vis = False)\n",
    "# net = VGG(num_classes=2, gap=False)\n",
    "checkpoint = torch.load(modelFile)\n",
    "net.load_state_dict(checkpoint['state_dict'])\n",
    "pretrained_clf = nn.DataParallel(net).cuda()\n",
    "pretrained_clf.eval()\n",
    "\n",
    "print(\"=======>load ISIC2016 dataset\")\n",
    "normalize = Normalize((0.7012, 0.5517, 0.4875), (0.0942, 0.1331, 0.1521))\n",
    "transform_test = torch_transforms.Compose([\n",
    "         RatioCenterCrop(0.8),\n",
    "         Resize((256,256)),\n",
    "         CenterCrop((224,224)),\n",
    "         ToTensor(),\n",
    "         normalize\n",
    "    ])\n",
    "\n",
    "trainset = ISIC(csv_file=trainCSVFile, transform=transform_test)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=False, num_workers=4)\n",
    "\n",
    "testset = ISIC(csv_file=testCSVFile, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PGD attack\n",
    "1. dataset attack\n",
    "2. single image attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "\n",
    "pgd_params = {\n",
    "            'ord': np.inf,\n",
    "            'y': None,\n",
    "            'eps': 5.0 / 255,\n",
    "            'eps_iter': 2.5 / 255,\n",
    "            'nb_iter': 5,\n",
    "            'rand_init': True,\n",
    "            'rand_minmax': 5.0 / 255,\n",
    "            'clip_min': 0.,\n",
    "            'clip_max': 1.,\n",
    "            'sanity_checks': True\n",
    "        }\n",
    "\n",
    "import libadver.attack as attack\n",
    "PGDAttack = attack.ProjectGradientDescent(model = pretrained_clf)\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "resultPath = 'adversarial_result/PGD/test_delete.csv'\n",
    "\n",
    "with open(resultPath, 'wt', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        image, label = data['image'], data['label']\n",
    "        image, label = image.cuda(), label.cuda()\n",
    "        \n",
    "        pgd_params['y'] = label\n",
    "        pgd_params['clip_min'] = torch.min(image) \n",
    "        pgd_params['clip_max'] = torch.max(image)\n",
    "        \n",
    "        adv_x = PGDAttack.generate(image, **pgd_params)\n",
    "        \n",
    "        pred_test, __, __ = pretrained_clf(adv_x)\n",
    "        predict = torch.argmax(pred_test, 1)\n",
    "        total += label.size(0)\n",
    "        correct += torch.eq(predict, label).sum().double().item()\n",
    "        # record test predicted responses\n",
    "        responses = F.softmax(pred_test, dim=1).squeeze().detach().cpu().numpy()\n",
    "        responses = [responses[i] for i in range(responses.shape[0])]\n",
    "        csv_writer.writerows(responses)\n",
    "        # log images\n",
    "#         I_test = utils.make_grid(image, nrow=8, normalize=True, scale_each=True)\n",
    "#         #writer.add_image('test/image', I_test, i)\n",
    "#         torchvision.utils.save_image(image, \"adversarial_result/PGD/test_image.jpg\", nrow=8, normalize=True)\n",
    "#         torchvision.utils.save_image(adv_x, \"adversarial_result/PGD/adv_image.jpg\", nrow=8, normalize=True)\n",
    "        \n",
    "#         # original attention maps\n",
    "#         __, a1, a2 = pretrained_clf(image)\n",
    "#         if a1 is not None:\n",
    "#             attn1 = visualize_attn(I_test, a1, up_factor=8, nrow=8)\n",
    "#             torchvision.utils.save_image(attn1, \"adversarial_result/PGD/att1.jpg\")\n",
    "#             #writer.add_image('test/attention_map_1', attn1, i)\n",
    "#         if a2 is not None:\n",
    "#             attn2 = visualize_attn(I_test, a2, up_factor=2*8, nrow=8)\n",
    "#             torchvision.utils.save_image(attn2, \"adversarial_result/PGD/att2.jpg\")\n",
    "            \n",
    "#         # adversarial attention maps\n",
    "#         __, a1, a2 = pretrained_clf(adv_x)\n",
    "#         if a1 is not None:\n",
    "#             attn1 = visualize_attn(I_test, a1, up_factor=8, nrow=8)\n",
    "#             torchvision.utils.save_image(attn1, \"adversarial_result/PGD/adv_att1.jpg\")\n",
    "#             #writer.add_image('test/attention_map_1', attn1, i)\n",
    "#         if a2 is not None:\n",
    "#             attn2 = visualize_attn(I_test, a2, up_factor=2*8, nrow=8)\n",
    "#             torchvision.utils.save_image(attn2, \"adversarial_result/PGD/adv_att2.jpg\")\n",
    "#         break\n",
    "                    #writer.add_image('test/attention_map_2', attn2, i)\n",
    "# AP, AUC, precision_mean, precision_mel, recall_mean, recall_mel = compute_metrics(resultPath, 'test.csv')\n",
    "# print(\"\\ntest result: accuracy %.2f%%\" % (100*correct/total))\n",
    "# print(\"\\nmean precision %.2f%% mean recall %.2f%% \\nprecision for mel %.2f%% recall for mel %.2f%%\" %\n",
    "#         (100*precision_mean, 100*recall_mean, 100*precision_mel, 100*recall_mel))\n",
    "# print(\"\\nAP %.4f AUC %.4f\\n\" % (AP, AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *\n",
    "resultPath = \"adversarial_result/PGD/test_m5n5.csv\"\n",
    "testCSVFile = \"/home/lrh/program/git/pytorch-example/adversarial-miccai2019/isic2016/IPMI2019-AttnMel/test.csv\"\n",
    "AP, AUC, precision_mean, precision_mel, recall_mean, recall_mel = compute_metrics(resultPath, testCSVFile)\n",
    "#print(\"\\ntest result: accuracy %.2f%%\" % (100*correct/total))\n",
    "print(\"\\nmean precision %.2f%% mean recall %.2f%% \\nprecision for mel %.2f%% recall for mel %.2f%%\" %\n",
    "        (100*precision_mean, 100*recall_mean, 100*precision_mel, 100*recall_mel))\n",
    "print(\"\\nAP %.4f AUC %.4f\\n\" % (AP, AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Image Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "from transforms import *\n",
    "import libadver\n",
    "\n",
    "pgd_params = {\n",
    "            'ord': np.inf,\n",
    "            'y': None,\n",
    "            'eps': 5.0 / 255,\n",
    "            'eps_iter': 1.25 / 255,\n",
    "            'nb_iter': 10,\n",
    "            'rand_init': True,\n",
    "            'rand_minmax': 5.0 / 255,\n",
    "            'clip_min': 0.,\n",
    "            'clip_max': 1.,\n",
    "            'sanity_checks': True\n",
    "        }\n",
    "\n",
    "pgd_params['y'] = torch.LongTensor([1,1,1,1,1]).cuda()\n",
    "\n",
    "\n",
    "import libadver.attack as attack\n",
    "PGDAttack = attack.ProjectGradientDescent(model = pretrained_clf)\n",
    "isBenign = False\n",
    "benignRoot = \"./adversarial_result/ori_img/benign\"\n",
    "malignantRoot = \"./adversarial_result/ori_img/malignant\"\n",
    "\n",
    "benignImgs = [\n",
    "    \"ISIC_0000234.jpg\",\"ISIC_0000254.jpg\", \"ISIC_0000271.jpg\", \n",
    "    \"ISIC_0000325.jpg\",\"ISIC_0000319.jpg\"\n",
    "]\n",
    "malignImgs = [\n",
    "    \"ISIC_0000549.jpg\", \"ISIC_0001103.jpg\", \"ISIC_0001142.jpg\",\n",
    "    \"ISIC_0000547.jpg\", \"ISIC_0001100.jpg\"\n",
    "]\n",
    "\n",
    "if isBenign is True:\n",
    "    Imgs = benignImgs\n",
    "    Root = benignRoot\n",
    "else:\n",
    "    Imgs = malignImgs\n",
    "    Root = malignantRoot\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "mean = [0.7012, 0.5517, 0.4875]\n",
    "std = [0.0942, 0.1331, 0.1521]\n",
    "normalize = Normalize(mean, std)\n",
    "transform_test = transforms.Compose([\n",
    "         RatioCenterCrop(0.8),\n",
    "         Resize((256,256)),\n",
    "         CenterCrop((224,224)),\n",
    "         ToTensor(),\n",
    "         normalize\n",
    "    ])\n",
    "\n",
    "images = torch.zeros([5,3,224,224])\n",
    "labels = torch.zeros([5])\n",
    "from PIL import Image\n",
    "for batchIdx, Img in enumerate(Imgs):\n",
    "    benignPath = os.path.join(Root, Img)\n",
    "    img = Image.open(benignPath)\n",
    "    sample = {'image': img, 'image_seg': img, 'label': 0}\n",
    "    t_sample = transform_test(sample)\n",
    "    img = t_sample[\"image\"]\n",
    "    #img.unsqueeze_(0)\n",
    "    images[batchIdx] = img\n",
    "    labels[batchIdx] = t_sample['label']\n",
    "    #print(images.shape)\n",
    "# print(img1.shape)\n",
    "images = images.cuda()\n",
    "pgd_params['clip_min'] = torch.min(images) \n",
    "pgd_params['clip_max'] = torch.max(images)\n",
    "\n",
    "# img1_temp = torch.zeros(img1.size())\n",
    "# for c2 in range(3):\n",
    "#     img1_temp.data[:,c2,:,:] = (img1.data[:,c2,:,:] * std[c2]) + mean[c2]\n",
    "# torchvision.utils.save_image(img1_temp, \"test/ori_img.jpg\", normalize=True,  scale_each=True)\n",
    "\n",
    "\n",
    "adv_images = PGDAttack.generate(images, **pgd_params)\n",
    "\n",
    "#torchvision.utils.save_image(images, \"adversarial_result/PGD/ori_img.png\", normalize=True,  scale_each=True)\n",
    "#torchvision.utils.save_image(adv_images, \"adversarial_result/PGD/adv_img.png\", normalize=True,  scale_each=True)\n",
    "delta_ims = adv_images - images\n",
    "#torchvision.utils.save_image(delta_ims, \"adversarial_result/PGD/delta_im.png\", normalize=True,  scale_each=True)\n",
    "\n",
    "\n",
    "pred_test, a1, a2 = pretrained_clf(images)\n",
    "print(torch.softmax(pred_test, dim=1))\n",
    "predict = torch.argmax(pred_test, 1)\n",
    "print(predict)\n",
    "\n",
    "pred_test, a1, a2 = pretrained_clf(adv_images)\n",
    "print(torch.softmax(pred_test, dim=1))\n",
    "predict = torch.argmax(pred_test, 1)\n",
    "print(predict)\n",
    "\n",
    "images = images.cpu()\n",
    "adv_images = adv_images.cpu()\n",
    "delta_ims = delta_ims.cpu()\n",
    "\n",
    "for i in range(5):\n",
    "    image = images[i]\n",
    "    image_PIL = libadver.visutils.recreate_image(image,mean,std)\n",
    "    libadver.visutils.save_image(image_PIL,\"adversarial_result/pre_img/malignant/ori_img_%d.png\" %i)\n",
    "    \n",
    "    adv_image = adv_images[i]\n",
    "    adv_image_PIL = libadver.visutils.recreate_image(adv_image,mean,std)\n",
    "    libadver.visutils.save_image(adv_image_PIL,\"adversarial_result/PGD/malignant/adv_img_%d.png\" %i)\n",
    "    \n",
    "    delta_im = delta_ims[i].data.numpy()\n",
    "    libadver.visutils.save_gradient_images(delta_im,\"adversarial_result/PGD/malignant/delta_im_%d.png\" %i)\n",
    "    \n",
    "    \n",
    "\n",
    "#I_test = utils.make_grid(img1.detach(), nrow=8, normalize=True, scale_each=True)\n",
    "\n",
    "# for c2 in range(3):\n",
    "#     img1_temp.data[:,c2,:,:] = (img1.data[:,c2,:,:] * std[c2]) + mean[c2]\n",
    "# torchvision.utils.save_image(img1_temp, \"test/adv_img.jpg\", normalize=True,  scale_each=True)\n",
    "\n",
    "# if a1 is not None:\n",
    "#     attn1 = visualize_attn(I_test, a1, up_factor=8, nrow=8)\n",
    "#     torchvision.utils.save_image(attn1, \"test/adv_att1.jpg\")\n",
    "#     #writer.add_image('test/attention_map_1', attn1, i)\n",
    "# if a2 is not None:\n",
    "#     attn2 = visualize_attn(I_test, a2, up_factor=2*8, nrow=8)\n",
    "#     torchvision.utils.save_image(attn2, \"test/adv_att2.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test draw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from libadver import visutils\n",
    "\n",
    "malignantRoot = \"./adversarial_result/pre_img/malignant\"\n",
    "malignImgs = [\n",
    "    \"ori_img_0.png\", \"ori_img_1.png\", \"ori_img_2.png\",\n",
    "    \"ori_img_3.png\", \"ori_img_4.png\"\n",
    "]\n",
    "malignantAdvRoot = \"./adversarial_result/PGD/malignant\"\n",
    "malignAdvImgs = [\n",
    "    \"adv_img_0.png\", \"adv_img_1.png\", \"adv_img_2.png\",\n",
    "    \"adv_img_3.png\", \"adv_img_4.png\"\n",
    "]\n",
    "\n",
    "\n",
    "# malignImg = malignImgs[0]\n",
    "# malignPath = os.path.join(malignantRoot, malignImg)\n",
    "# img = Image.open(malignPath)\n",
    "# text = \"Malignant:98.93%\"\n",
    "# img_text = visutils.draw_text(img,text,'green',length=180)\n",
    "# img_text.save(os.path.join(malignantRoot, \"ori_img_0_text.png\"))\n",
    "\n",
    "malignAdvImg = malignAdvImgs[0]\n",
    "malignAdvPath = os.path.join(malignantAdvRoot, malignAdvImg)\n",
    "advImg = Image.open(malignAdvPath)\n",
    "text = \"Benign:100%\"\n",
    "advImg_text = visutils.draw_text(advImg,text,'red',length=180)\n",
    "advImg_text.save(os.path.join(malignantAdvRoot, \"adv_img_0_text.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAP attack\n",
    "1. dataset attack\n",
    "2. single image attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attackModelPath': None, 'mag_in': 7.0, 'ord': 'inf', 'epochNum': 3, 'criterion': CrossEntropyLoss(), 'ncInput': 3, 'ncOutput': 3, 'mean': (0.7012, 0.5517, 0.4875), 'std': (0.0942, 0.1331, 0.1521), 'MaxIter': 100}\n",
      "===>Train\n",
      "\n",
      " Epoch : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lrh/program/git/pytorch-example/Adversarial_Perturbations/adversarial/libadver/libadver/attack/generative_adversarial_perturbations.py:193: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  delta_im[i,ci,:,:].data *= torch.tensor(np.minimum(1.0, mag_in_scaled_c / l_inf_channel)).float().cuda()\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'libadver.utils' has no attribute 'progress_bar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d8ab62944c50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"optimizerG\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizerG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mGAPAttack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerativeAdversarialPerturbations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattackModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mGAPAttack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveModelPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===>Test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/program/git/pytorch-example/Adversarial_Perturbations/adversarial/libadver/libadver/attack/generative_adversarial_perturbations.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainLoader, saveModelPath)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 utils.progress_bar(batchIdx, len(trainLoader), 'loss:%.3f | Acc: %.3f%% (%d/%d)'\n\u001b[0m\u001b[1;32m     92\u001b[0m                             % (loss, 100.*float(correct)/total, correct, total))\n\u001b[1;32m     93\u001b[0m             \u001b[0mcurAcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100.\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'libadver.utils' has no attribute 'progress_bar'"
     ]
    }
   ],
   "source": [
    "import libadver.attack as attack\n",
    "import libadver.models.generators as generators\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "mean = (0.7012, 0.5517, 0.4875)\n",
    "std = (0.0942, 0.1331, 0.1521)\n",
    "isTrain = True\n",
    "import torch\n",
    "\n",
    "params = {\n",
    "        \"attackModelPath\" : None,\n",
    "        \"mag_in\" : 7.0,\n",
    "        \"ord\" : \"inf\",\n",
    "        \"epochNum\" : 3,\n",
    "        \"criterion\" : nn.CrossEntropyLoss(),\n",
    "        \"ncInput\" : 3,\n",
    "        \"ncOutput\" : 3,\n",
    "        \"mean\" : mean,\n",
    "        \"std\" : std,\n",
    "        \"MaxIter\" : 100\n",
    "    }\n",
    "print(params)\n",
    "saveModelPath = \"adversarial_result/GAP/GAP_im_m7n3.pth\"\n",
    "attackModel = generators.define(input_nc = params[\"ncInput\"], output_nc = params[\"ncOutput\"],\n",
    "                                ngf = 64, gen_type = \"unet\", norm=\"batch\", act=\"relu\", gpu_ids = [0])\n",
    "    \n",
    "\n",
    "if isTrain is True:\n",
    "    print(\"===>Train\")\n",
    "    optimizerG = optim.Adam(attackModel.parameters(), lr = 2e-4, betas = (0.5, 0.999))\n",
    "    params[\"optimizerG\"] = optimizerG\n",
    "    GAPAttack = attack.GenerativeAdversarialPerturbations(pretrained_clf, attackModel, **params)\n",
    "    GAPAttack.train(trainloader, saveModelPath)\n",
    "else:\n",
    "    print(\"===>Test\")\n",
    "    ## test\n",
    "    params[\"attackModelPath\"] = saveModelPath\n",
    "    GAPAttack = attack.GenerativeAdversarialPerturbations(pretrained_clf, attackModel, **params)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(testloader):\n",
    "        images, targets = data['image'].cuda(), data['label'].cuda()\n",
    "        adv_images = GAPAttack.generate(images)\n",
    "        predicted,_,_ = pretrained_clf(adv_images)\n",
    "        predicted_labels = torch.argmax(predicted,1)\n",
    "        #print(predicted_labels)\n",
    "        correct += torch.sum(predicted_labels.eq(targets))\n",
    "        #print(targets)\n",
    "        total += images.shape[0]\n",
    "        print(\"ACC:%.3f | %d,%d\" %(100.0*float(correct) / total, correct, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visulization\n",
    "\n",
    "ori_img + conv1 feas + saliency maps + attention maps + Guided gradCam\n",
    "\n",
    "//vistools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libadver.visutils as visutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transforms import *\n",
    "from torchvision.transforms import transforms\n",
    "benignImg = \"./test/ori_img/ISIC_0000016_be.jpg\" #0\n",
    "malignImg = \"./test/ori_img/ISIC_0000074_ma.jpg\" #1\n",
    "target_class = 1\n",
    "img1 = Image.open(malignImg)\n",
    "\n",
    "mean = (0.7012, 0.5517, 0.4875)\n",
    "std = (0.0942, 0.1331, 0.1521)\n",
    "normalize = Normalize(mean, std)\n",
    "transform_test = transforms.Compose([\n",
    "         RatioCenterCrop(0.8),\n",
    "         Resize((256,256)),\n",
    "         CenterCrop((224,224)),\n",
    "         ToTensor(),\n",
    "         normalize\n",
    "    ])\n",
    "\n",
    "sample = {'image': img1, 'image_seg': img1, 'label': 0}\n",
    "\n",
    "t_sample = transform_test(sample)\n",
    "img1 = t_sample[\"image\"]\n",
    "img1.unsqueeze_(0)\n",
    "img1 = img1.cuda()\n",
    "\n",
    "x = img1\n",
    "x.requires_grad = True\n",
    "output,_,_ = pretrained_clf(x)\n",
    "\n",
    "\n",
    "one_hot_output = torch.FloatTensor(1, output.size()[-1]).zero_()\n",
    "one_hot_output[0][target_class] = 1\n",
    "one_hot_output = one_hot_output.cuda()\n",
    "# Backward pass\n",
    "output.backward(gradient=one_hot_output)\n",
    "print(x.grad.data.shape)\n",
    "gradient_arr = x.grad.data.cpu().numpy()[0]\n",
    "gradient_arr_grey = visutils.convert_to_grayscale(gradient_arr)\n",
    "print(gradient_arr_grey.shape)\n",
    "gradient_arr_grey = 1 - gradient_arr_grey\n",
    "visutils.save_gradient_images(gradient_arr_grey, \"test/malignImg_grey.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transforms import *\n",
    "from torchvision.transforms import transforms\n",
    "benignImg = \"./test/ori_img/ISIC_0000016_be.jpg\" #0\n",
    "malignImg = \"./test/ori_img/ISIC_0000074_ma.jpg\" #1\n",
    "target_class = 1\n",
    "img1 = Image.open(malignImg)\n",
    "\n",
    "mean = (0.7012, 0.5517, 0.4875)\n",
    "std = (0.0942, 0.1331, 0.1521)\n",
    "normalize = Normalize(mean, std)\n",
    "transform_test = transforms.Compose([\n",
    "         RatioCenterCrop(0.8),\n",
    "         Resize((256,256)),\n",
    "         CenterCrop((224,224)),\n",
    "         ToTensor(),\n",
    "         normalize\n",
    "    ])\n",
    "\n",
    "sample = {'image': img1, 'image_seg': img1, 'label': 0}\n",
    "\n",
    "t_sample = transform_test(sample)\n",
    "img1 = t_sample[\"image\"]\n",
    "img1.unsqueeze_(0)\n",
    "img1 = img1.cuda()\n",
    "\n",
    "x = img1\n",
    "_,_,_,block1,block2,block3,block4,block5 = pretrained_clf(x)\n",
    "\n",
    "print(block1.shape)\n",
    "import torchvision\n",
    "block1 = block1.permute([1,0,2,3])\n",
    "torchvision.utils.save_image(block1,\"test/block1.jpg\")\n",
    "\n",
    "block2 = block2.permute([1,0,2,3])\n",
    "torchvision.utils.save_image(block2,\"test/block2.jpg\")\n",
    "\n",
    "block3 = block3.permute([1,0,2,3])\n",
    "torchvision.utils.save_image(block3,\"test/block3.jpg\",nrow=32)\n",
    "\n",
    "block4 = block4.permute([1,0,2,3])\n",
    "torchvision.utils.save_image(block4,\"test/block4.jpg\",nrow=32)\n",
    "\n",
    "block5 = block5.permute([1,0,2,3])\n",
    "torchvision.utils.save_image(block5,\"test/block5.jpg\",nrow=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "crashes = sns.load_dataset(\"car_crashes\").sort_values(\"total\", ascending=False)[0:7]\n",
    "print(crashes.head())\n",
    "# 加载数据\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 3))\n",
    "# 创建图表\n",
    "\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(x=\"total\", y=\"abbrev\", data=crashes,\n",
    "            label=\"Total\", color=\"b\",edgecolor = 'w')\n",
    "# 设置第一个柱状图\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x=\"alcohol\", y=\"abbrev\", data=crashes,\n",
    "            label=\"Alcohol-involved\", color=\"b\",edgecolor = 'w')\n",
    "# 设置第二个柱状图\n",
    "\n",
    "ax.legend(ncol=1, loc=\"lower right\")\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "resnext = models.resnext101_32x8d(pretrained=True)\n",
    "\n",
    "#print(resnext)\n",
    "\n",
    "resnet = models.resnet18()\n",
    "#print(resnet)\n",
    "\n",
    "print(resnext)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
